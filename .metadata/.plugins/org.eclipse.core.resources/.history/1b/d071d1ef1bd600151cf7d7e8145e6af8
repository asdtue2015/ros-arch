// Copyright 2015 Open Source Robotics Foundation, Inc.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

#ifndef IMAGE_PIPELINE__IMAGE_VIEW_NODE_HPP_
#define IMAGE_PIPELINE__IMAGE_VIEW_NODE_HPP_
#include <gst/gst.h>
#include <glib.h>
#include <gst/app/gstappsink.h>
#include <gio/gio.h>
#include <string>
#include "opencv2/highgui/highgui.hpp"
#include "rclcpp/rclcpp.hpp"
#include "sensor_msgs/msg/image.hpp"
#include "../Aux/common.hpp"


static GThread* thread;
static GMainLoop *loop;
static GstBus *bus;
static guint bus_watch_id;

class GImage
{

public:
	size_t sizeInBytes=0;
	guint height, width=0;
	guchar *data=NULL;
	guchar*  Gst_encoding=NULL;
};


static gboolean
bus_call (GstBus  *bus, GstMessage *msg, gpointer  data)
{
  GMainLoop *loop = (GMainLoop *) data;

  switch (GST_MESSAGE_TYPE (msg)) {

    case GST_MESSAGE_EOS:
      g_print ("End of stream\n");
      break;

    case GST_MESSAGE_ERROR: {
      gchar  *debug;
      GError *error;

      gst_message_parse_error (msg, &error, &debug);
      g_free (debug);

      g_printerr ("Error: %s\n", error->message);
      g_error_free (error);
      break;
    }
    default:
      break;
  }

  return TRUE;
}



void play()
{
              GMainLoop *loop = g_main_loop_new(NULL, FALSE);
              g_main_loop_run(loop);
}






static void  cb_need_data (GstElement *appsrc,guint usize, gpointer Gimage)
{
	   GstBuffer *buffer;
	   GstMapInfo map;
	   static GstClockTime timestamp=0;
	   GstFlowReturn ret;
	   GImage* Gframe = (GImage *) Gimage;


	  //buffer = gst_buffer_new_allocate (NULL, Gframe->sizeInBytes, NULL);

	   //gst_buffer_map (buffer, &map, GST_MAP_WRITE);
	   //memcpy( (guchar *)map.data, Gframe->data,  gst_buffer_get_size( buffer ) );
	   buffer =gst_buffer_new_wrapped (Gframe->data,Gframe->sizeInBytes);

	   //GST_BUFFER_PTS (buffer) = timestamp;
	   //GST_BUFFER_DURATION (buffer) = gst_util_uint64_scale_int (1, GST_SECOND, 2);
	   //GST_BUFFER_DURATION (buffer)=GST_CLOCK_TIME_NONE;
	   //timestamp += GST_BUFFER_DURATION (buffer);

	    g_signal_emit_by_name (appsrc, "push-buffer", buffer, &ret);

	    if (ret != GST_FLOW_OK)
	    {
	     	      g_main_loop_quit (loop);
	    }
}




// Node which receives sensor_msgs/Image messages and renders them using OpenCV.
class Streamer : public rclcpp::Node
{

private:
  rclcpp::Subscription<sensor_msgs::msg::Image>::SharedPtr sub_;


    cv::Mat frame_;
    //static GMainLoop *loop;
    bool VidSource_initialised=false;
    GImage* Gframe= new GImage();
    GstElement *pipeline, *appsrc, *jpeg_encoder, *rtpjpeg_payload, *conv, *udpsink, *videosink;

public: explicit Streamer( const std::string & input, const std::string & node_name = "streamer_node")
  	  	  	  	 : Node(node_name, true)
{

	/*Initialise Gstreamer */
		   gst_init (NULL, NULL);

    // Create a subscription on the input topic.
    sub_ = this->create_subscription<sensor_msgs::msg::Image>(input, [node_name, this](const sensor_msgs::msg::Image::SharedPtr msg)

{
  //Create a cv::Mat from the image message (without copying).
   cv::Mat frame_(msg->width, msg->height,encoding2mat_type(msg->encoding), msg->data.data());
   this->frame_=frame_;
   Gframe->data=(guchar *)frame_.data;
   if (! VidSource_initialised)

   {
    //Get frame properties
	       Gframe->sizeInBytes = frame_.step[0] * frame_.rows;
	  	   Gframe->height = (guint)frame_.rows;
	  	   Gframe->width  = (guint)frame_.cols;
	  	   Gframe->data   = (guchar *)frame_.data;
	  	   Gframe->Gst_encoding = (guchar*)mat_type2GSTencoding(frame_.type());

	 //setup pipeline
	    pipeline  = gst_pipeline_new ("pipeline");
	    appsrc    = gst_element_factory_make ("appsrc", "source");
	    jpeg_encoder = gst_element_factory_make("jpegenc", "encoder");
	    rtpjpeg_payload = gst_element_factory_make("rtpjpegpay", "rtppay");
	    conv      = gst_element_factory_make ("videoconvert", "conv");
	    videosink = gst_element_factory_make ("autovideosink", "videosink");
	    udpsink   =  gst_element_factory_make ("udpsink", "sink");


	    if (!pipeline || !appsrc || !jpeg_encoder || !rtpjpeg_payload || !udpsink)
	    {
	        g_printerr ("One element could not be created. Exiting.\n");
	        return -1;
	    }


	  /*Setup appsrc*/
	    g_object_set (G_OBJECT (appsrc), "caps",
	    gst_caps_new_simple ("video/x-raw", "format", G_TYPE_STRING, "GRAY8", "width", G_TYPE_INT, Gframe->width, "height", G_TYPE_INT, Gframe->height, "framerate", GST_TYPE_FRACTION, 0, 1,NULL), NULL);
	    //g_object_set (G_OBJECT (appsrc),"stream-type", 0, "format", GST_FORMAT_TIME, NULL);
	    g_signal_connect (appsrc, "need-data", G_CALLBACK (cb_need_data), Gframe);

	  /*SetUp UDP-sink*/
	    g_object_set(G_OBJECT(udpsink), "host", "127.0.0.1", NULL);
	    g_object_set(G_OBJECT(udpsink), "port", 5000, NULL);


	  /* we add a message handler */
	   	//bus = gst_pipeline_get_bus (GST_PIPELINE (pipeline));
	   	//bus_watch_id = gst_bus_add_watch (bus, bus_call, loop);
		//gst_object_unref (bus);


	   	/* Handle bus messages */
	   	GstMessage * msg;
			while ((msg = gst_bus_pop (bus)))
			{
					  // Call your bus message handler
					  bus_call (bus, msg, NULL);
					  gst_message_unref (msg);
			 }


	   /* Connect the pipeline elements */
	     // gst_bin_add_many (GST_BIN (pipeline), appsrc, jpeg_encoder, rtpjpeg_payload, udpsink, NULL);
		//gst_element_link_many (appsrc, jpeg_encoder, rtpjpeg_payload, udpsink, NULL);
		gst_bin_add_many (GST_BIN (pipeline), appsrc,conv, videosink, NULL);

       VidSource_initialised = true;

        }


         gst_element_link_many (appsrc,conv, videosink, NULL);

        /* play */
         const char* str= "LiveCamera";
         g_print ("Now playing: %s\n", str);
         gst_element_set_state (pipeline, GST_STATE_PLAYING);


   std::stringstream ss;
   ss << "pid: " << GETPID() << ", ptr: " << msg.get();
   draw_on_image(frame_, ss.str(), 60);
   // Show the image.
   CvMat c_mat = frame_;



   cvShowImage(node_name.c_str(), &c_mat);
   /* play */
           //	gst_element_set_state (pipeline, GST_STATE_PLAYING);
           	//g_main_loop_run (loop);




   char key = cv::waitKey(1);    // Look for key presses.
   if (key == 27 /* ESC */ || key == 'q') {
     rclcpp::shutdown();
   }
   if (key == ' ') {    // If <space> then pause until another <space>.
     key = '\0';
     while (key != ' ') {
       key = cv::waitKey(1);
     }
   }
 }, rmw_qos_profile_sensor_data);
}
};





#endif  // IMAGE_PIPELINE__IMAGE_VIEW_NODE_HPP_
